import threading
import os
import datetime
from flask import request, jsonify, g
import PIL.Image

# --- IMPORTS ---
from services.llama_service import LlamaService
# [THAY ƒê·ªîI 1] Import GroqService thay v√¨ GeminiService
from services.groq_service import GroqService 
from services.integration_service import IntegrationService
from models.recommendation_model import RecommendationModel
from exceptions.exceptions import ValidationError

# --- INIT SERVICES ---
llama_service = LlamaService()
# [THAY ƒê·ªîI 2] Kh·ªüi t·∫°o GroqService
groq_service = GroqService()
integration_service = IntegrationService()
rec_model = RecommendationModel()

def async_pipeline(user_id, token, record_id, options):
    print(f"üöÄ START Analysis: {record_id}")
    temp_path = None
    
    try:
        # 1. L·∫•y metadata
        meta = integration_service.get_medical_record_meta(record_id, token)
        if not meta: 
            print("‚ùå Cannot fetch record metadata")
            return
        
        # 2. T·∫£i file v·ªÅ
        temp_path = integration_service.download_file(meta['fileUrl'])
        if not temp_path: 
            print("‚ùå Cannot download file")
            return

        # 3. Ph√¢n lo·∫°i & Tr√≠ch xu·∫•t d·ªØ li·ªáu
        ext = meta['fileUrl'].split('.')[-1].lower() if '.' in meta['fileUrl'] else 'txt'
        
        health_data = {}
        raw_text = ""

        if ext in ['jpg', 'png', 'jpeg', 'webp']:
            print("üì∏ Image Mode: Processing with Groq Vision")
            img = PIL.Image.open(temp_path)
            # [THAY ƒê·ªîI 3] D√πng groq_service cho ·∫£nh
            health_data = groq_service.extract_health_data(img, is_image=True)
            raw_text = "[Image Content Processed]"

        elif ext == 'txt':
            print("üìÑ Text Mode: Reading raw text file")
            with open(temp_path, 'r', encoding='utf-8') as f:
                raw_text = f.read()
            # [THAY ƒê·ªîI 4] D√πng groq_service cho text
            health_data = groq_service.extract_health_data(raw_text, is_image=False)

        elif ext == 'pdf':
            print("üìë PDF Mode: Sending to LlamaParse")
            # D√πng LlamaParse ƒë·ªÉ l·∫•y text t·ª´ PDF
            raw_text = llama_service.parse_pdf_to_markdown(temp_path)
            # [THAY ƒê·ªîI 5] D√πng groq_service ph√¢n t√≠ch text t·ª´ PDF
            health_data = groq_service.extract_health_data(raw_text, is_image=False)
            
        else:
            print(f"‚ö†Ô∏è Unsupported file extension: {ext}")
            return

        # 4. CALLBACK: C·∫≠p nh·∫≠t Health Service
        integration_service.callback_health_update(record_id, health_data, raw_text)

        # 5. Recommendation (AI Logic)
        # G·ªçi Recipe Service ƒë·ªÉ l·∫•y danh s√°ch m√≥n ƒÉn
        recipes = integration_service.search_recipes() 
        
        # [THAY ƒê·ªîI 6] D√πng groq_service ƒë·ªÉ g·ª£i √Ω m√≥n ƒÉn
        rec_result = groq_service.recommend_recipes(health_data, recipes, options)

        # 6. Save Recommendation
        doc = {
            "userId": user_id,
            "medicalRecordId": record_id,
            "recommendations": rec_result.get('recommendations', []),
            "analysisSummary": rec_result.get('analysisSummary', ''),
            "createdAt": datetime.datetime.utcnow().isoformat()
        }
        rec_model.create(doc)
        print(f"üéâ Analysis Pipeline Done for {record_id}")

    except Exception as e:
        print(f"üî• Pipeline Error: {e}")
    finally:
        # D·ªçn d·∫πp file r√°c
        if temp_path and os.path.exists(temp_path): 
            try:
                os.remove(temp_path)
            except: pass

def trigger_analysis():
    data = request.json
    record_id = data.get('medicalRecordId')
    options = data.get('options', {})
    token = request.headers.get('Authorization')

    if not record_id:
        return jsonify({"message": "Missing medicalRecordId"}), 400

    # Ch·∫°y ng·∫ßm (Fire & Forget)
    thread = threading.Thread(target=async_pipeline, args=(g.user_id, token, record_id, options))
    thread.start()

    return jsonify({"message": "Processing started", "analysisId": record_id}), 202

def chat_with_ai():
    """
    API Chat v·ªõi AI
    """
    data = request.json
    message = data.get('message')
    context = data.get('context', {})
    
    if not message:
        raise ValidationError("Message is required")
        
    # [THAY ƒê·ªîI 7] D√πng groq_service ƒë·ªÉ chat
    reply = groq_service.chat_nutrition(message, context)
    
    return jsonify({
        "message": reply,
        "conversationId": context.get("conversationId", "new_conv"),
        "relatedRecipes": [],
        "sources": [{"type": "ai_generated", "title": "Llama 3 (via Groq)"}]
    }), 200